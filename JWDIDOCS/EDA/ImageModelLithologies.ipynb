{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnetics Sources : \n",
    "https://dataservices.gfz-potsdam.de/intermagnet/showshort.php?id=cfc7a77f-12cc-11ef-967a-4ffbfe06208e\n",
    "\n",
    "https://resources.vic.gov.au/geology-exploration/maps-reports-data/geophysics\n",
    "\n",
    "https://resources.vic.gov.au/geology-exploration/maps-reports-data/geophysics\n",
    "\n",
    "\n",
    "\n",
    "Reference material: https://opticalengineering.spiedigitallibrary.org/journals/journal-of-applied-remote-sensing/volume-13/issue-1/016513/Lithologic-classification-using-multilevel-spectral-characteristics/10.1117/1.JRS.13.016513.full\n",
    "\n",
    "\n",
    "\n",
    "# Labeling source : \n",
    "Guangxhi : https://ikcest-drr.data.ac.cn/map/m02d7\n",
    "\n",
    "\n",
    "WA Geology : \n",
    "https://www.dmp.wa.gov.au/Geological-Survey/Geology-and-Geophysics-1387.aspx\n",
    "\n",
    "Western Australia - Lithology domains : file:///C:/Users/joshc/Downloads/gsdplan_mapwa2015_2500_ed14.pdf\n",
    "\n",
    "\n",
    "\n",
    "Western Australia Electromagnetics : \n",
    "https://geodownloads.dmp.wa.gov.au/downloads/geophysics/72374/\n",
    "\n",
    "\n",
    "\n",
    "Look at the data distributions by lithology domains and do some clustering etc. explore this data:::\n",
    "Western Australia - Geochem - Point Data : https://geochem.dmp.wa.gov.au/geochem/\n",
    "\n",
    "\n",
    "WA Magnetics : \n",
    "https://www.dmp.wa.gov.au/Geological-Survey/Magnetotelluric-MT-surveys-31324.aspx   \n",
    "\n",
    "Gravity Anomaly Grid: https://geodownloads.dmp.wa.gov.au/downloads/geophysics/72203/\n",
    "\n",
    "\n",
    "### To Do : use Qgis to make polygons -> cut out sections \n",
    "\n",
    "\n",
    "```\n",
    "Find lithologies of an area \n",
    "Make some cut outs \n",
    "Train\n",
    "Test etc.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import fiona \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1385736425.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    import\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from io import BytesIO,StringIO\n",
    "from zipfile import ZipFile\n",
    "import re,os\n",
    "import numpy as np\n",
    "import xml.sax, xml.sax.handler\n",
    "from html.parser import HTMLParser\n",
    "import pandas as pd\n",
    "import \n",
    "\n",
    "\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialize the base class\n",
    "        HTMLParser.__init__(self)\n",
    "        self.inTable=False\n",
    "        self.mapping = {} \n",
    "        self.buffer = \"\"\n",
    "        self.name_tag = \"\"\n",
    "        self.series = pd.Series()\n",
    "        \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'table':\n",
    "            self.inTable = True\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.inTable:\n",
    "            self.buffer = data.strip(' \\n\\t').split(':')\n",
    "            if len(self.buffer)==2:\n",
    "                self.mapping[self.buffer[0]]=self.buffer[1]\n",
    "                self.series = pd.Series(self.mapping)\n",
    "        \n",
    "class PlacemarkHandler(xml.sax.handler.ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.inName = False # handle XML parser events\n",
    "        self.inPlacemark = False\n",
    "        self.mapping = {} \n",
    "        self.buffer = \"\"\n",
    "        self.name_tag = \"\"\n",
    "        \n",
    "    def startElement(self, name, attributes):\n",
    "        if name == \"Placemark\": # on start Placemark tag\n",
    "            self.inPlacemark = True\n",
    "            self.buffer = \"\" \n",
    "        if self.inPlacemark:\n",
    "            if name == \"name\": # on start title tag\n",
    "                self.inName = True # save name text to follow\n",
    "            \n",
    "    def characters(self, data):\n",
    "        if self.inPlacemark: # on text within tag\n",
    "            self.buffer += data # save text if in title\n",
    "            \n",
    "    def endElement(self, name):\n",
    "        self.buffer = self.buffer.strip('\\n\\t')\n",
    "        \n",
    "        if name == \"Placemark\":\n",
    "            self.inPlacemark = False\n",
    "            self.name_tag = \"\" #clear current name\n",
    "        \n",
    "        elif name == \"name\" and self.inPlacemark:\n",
    "            self.inName = False # on end title tag            \n",
    "            self.name_tag = self.buffer.strip()\n",
    "            self.mapping[self.name_tag] = {}\n",
    "        elif self.inPlacemark:\n",
    "            if name in self.mapping[self.name_tag]:\n",
    "                self.mapping[self.name_tag][name] += self.buffer\n",
    "            else:\n",
    "                self.mapping[self.name_tag][name] = self.buffer\n",
    "        self.buffer = \"\"\n",
    "        \n",
    "        \n",
    "    def spatializer(row):\n",
    "        \"\"\"\n",
    "        Function to convert string objects to Python spatial objects\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #############################\n",
    "        # coordinates field\n",
    "        #############################\n",
    "        try:\n",
    "            # look for the coordinates column\n",
    "            data = row['coordinates'].strip(' \\t\\n\\r')\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        import ast\n",
    "        lsp = data.strip().split(' ')\n",
    "        linestring = map(lambda x: ast.literal_eval(x),lsp)\n",
    "        try:\n",
    "            spatial = Polygon(LineString(linestring))\n",
    "            convertedpoly = pd.Series({'geometry':spatial})\n",
    "            return convertedpoly\n",
    "        except:\n",
    "            try:\n",
    "                g = ast.literal_eval(data)\n",
    "                points = pd.Series({'geometry':Point(g[:2]),\n",
    "                                   'altitude':g[-1]})\n",
    "                return points\n",
    "            except:\n",
    "            \n",
    "                pass\n",
    "            \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # Test for latitude and longitude columns\n",
    "            lat=float(row['latitude'])\n",
    "            lon=float(row['longitude'])\n",
    "            point = Point(lon,lat)\n",
    "            convertedpoly = pd.Series({'geometry':point})\n",
    "            return convertedpoly\n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "    def htmlizer(row):\n",
    "        htmlparser = MyHTMLParser()\n",
    "        htmlparser.feed(row['description'])\n",
    "        return htmlparser.series\n",
    "        \n",
    "        \n",
    "def keyholemarkup2x(file,output='df'):\n",
    "    \"\"\"\n",
    "    Takes Keyhole Markup Language Zipped (KMZ) or KML file as input. The  \n",
    "    output is a pandas dataframe, geopandas geodataframe, csv, geojson, or\n",
    "    shapefile.\n",
    "    \n",
    "    All core functionality from:\n",
    "    http://programmingadvent.blogspot.com/2013/06/kmzkml-file-parsing-with-python.html\n",
    "    \n",
    "    Parameters\n",
    "        ----------\n",
    "        file : {string}\n",
    "            The string path to your KMZ or .\n",
    "        output : {string}\n",
    "            Defines the type of output. Valid selections include:\n",
    "                - shapefile - 'shp', 'shapefile', or 'ESRI Shapefile'\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "    \"\"\"\n",
    "    r = re.compile(r'(?<=\\.)km+[lz]?',re.I)\n",
    "    try:\n",
    "        extension = r.search(file).group(0) #(re.findall(r'(?<=\\.)[\\w]+',file))[-1]\n",
    "        \n",
    "    \n",
    "    except IOError as e:\n",
    "        logging.error(\"I/O error {0}\".format(e))\n",
    "    if (extension.lower()=='kml') is True:\n",
    "        buffer = file\n",
    "    elif (extension.lower()=='kmz') is True:\n",
    "        kmz = ZipFile(file, 'r')\n",
    "        \n",
    "        vmatch = np.vectorize(lambda x:bool(r.search(x)))\n",
    "        A = np.array(kmz.namelist())\n",
    "        sel = vmatch(A)\n",
    "        buffer = kmz.open(A[sel][0],'r')\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Incorrect file format entered.  Please provide the '\n",
    "                         'path to a valid KML or KMZ file.')    \n",
    "     \n",
    "    \n",
    "    parser = xml.sax.make_parser()\n",
    "    handler = PlacemarkHandler()\n",
    "    parser.setContentHandler(handler)\n",
    "    parser.parse(buffer)\n",
    "    \n",
    "    try:\n",
    "        kmz.close()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df = pd.DataFrame(handler.mapping).T\n",
    "    names = list(map(lambda x: x.lower(),df.columns))\n",
    "    if 'description' in names:\n",
    "        extradata = df.apply(PlacemarkHandler.htmlizer,axis=1)\n",
    "        df = df.join(extradata)\n",
    "    \n",
    "    \n",
    "    output = output.lower()\n",
    "    \n",
    "    if output=='df' or output=='dataframe' or output == None:\n",
    "        result = df\n",
    "        \n",
    "    elif output=='csv':\n",
    "        out_filename = file[:-3] + \"csv\"\n",
    "        df.to_csv(out_filename,encoding='utf-8',sep=\"\\t\")\n",
    "        result = (\"Successfully converted {0} to CSV and output to\"\n",
    "                   \" disk at {1}\".format(file,out_filename))\n",
    "        \n",
    "    elif output=='gpd' or output == 'gdf' or output=='geoframe' or output == 'geodataframe':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        result = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        \n",
    "        \n",
    "    elif output=='geojson' or output=='json':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "        try:\n",
    "            import geojson\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geojson. {0}'.format(e))\n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        gdf = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        out_filename = file[:-3] + \"geojson\"\n",
    "        gdf.to_file(out_filename,driver='GeoJSON')\n",
    "        validation = geojson.is_valid(geojson.load(open(out_filename)))['valid']\n",
    "        if validation == 'yes':\n",
    "            \n",
    "            result = (\"Successfully converted {0} to GeoJSON and output to\"\n",
    "                      \" disk at {1}\".format(file,out_filename))\n",
    "        else:\n",
    "            raise ValueError('The geojson conversion did not create a '\n",
    "                            'valid geojson object. Try to clean your '\n",
    "                            'data or try another file.')\n",
    "            \n",
    "    elif output=='shapefile' or output=='shp' or output =='esri shapefile':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "            \n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "            \n",
    "        try:\n",
    "            import shapefile\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires pyshp. {0}'.format(e))\n",
    "        \n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        gdf = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        out_filename = file[:-3] + \"shp\"\n",
    "        gdf.to_file(out_filename,driver='ESRI Shapefile')\n",
    "        sf = shapefile.Reader(out_filename)\n",
    "        import shapefile\n",
    "        sf = shapefile.Reader(out_filename)\n",
    "        if len(sf.shapes())>0:\n",
    "            validation = \"yes\"\n",
    "        else:\n",
    "            validation = \"no\"\n",
    "        if validation == 'yes':\n",
    "            \n",
    "            result = (\"Successfully converted {0} to Shapefile and output to\"\n",
    "                      \" disk at {1}\".format(file,out_filename))\n",
    "        else:\n",
    "            raise ValueError('The Shapefile conversion did not create a '\n",
    "                            'valid shapefile object. Try to clean your '\n",
    "                            'data or try another file.') \n",
    "    else:\n",
    "        raise ValueError('The conversion returned no data; check if'\n",
    "                        ' you entered a correct output file type. '\n",
    "                        'Valid output types are geojson, shapefile,'\n",
    "                        ' csv, geodataframe, and/or pandas dataframe.')\n",
    "        \n",
    "    return result\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide at least a geometry column or a field",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# output to geopandas\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# a = keyholemarkup2x('WA_400m_Grav_Merge_v1_2020.kmz',output='gpd')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# plot this new file, use %matplotlib inline if you are in a notebook\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#%matplotlib inline\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# a.plot()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# convert to shapefile\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mkeyholemarkup2x\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWA_400m_Grav_Merge_v1_2020.kmz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 276\u001b[0m, in \u001b[0;36mkeyholemarkup2x\u001b[1;34m(file, output)\u001b[0m\n\u001b[0;32m    274\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(pd\u001b[38;5;241m.\u001b[39mconcat([df,geos],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    275\u001b[0m out_filename \u001b[38;5;241m=\u001b[39m file[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 276\u001b[0m \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mESRI Shapefile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m sf \u001b[38;5;241m=\u001b[39m shapefile\u001b[38;5;241m.\u001b[39mReader(out_filename)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshapefile\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\geodataframe.py:1536\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[1;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m \n\u001b[0;32m   1443\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1532\u001b[0m \n\u001b[0;32m   1533\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[1;32m-> 1536\u001b[0m \u001b[43m_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\io\\file.py:686\u001b[0m, in \u001b[0;36m_to_file\u001b[1;34m(df, filename, driver, schema, index, mode, crs, engine, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 686\u001b[0m     \u001b[43m_to_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    688\u001b[0m     _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\io\\file.py:748\u001b[0m, in \u001b[0;36m_to_file_pyogrio\u001b[1;34m(df, filename, driver, schema, crs, mode, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoDataFrame cannot contain duplicated column names.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 748\u001b[0m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyogrio\\geopandas.py:662\u001b[0m, in \u001b[0;36mwrite_dataframe\u001b[1;34m(df, path, layer, driver, encoding, geometry_type, promote_to_multi, nan_as_null, append, use_arrow, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    660\u001b[0m     geometry \u001b[38;5;241m=\u001b[39m to_wkb(geometry\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m--> 662\u001b[0m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyogrio\\raw.py:723\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(path, geometry, field_data, fields, field_mask, layer, driver, geometry_type, crs, encoding, promote_to_multi, nan_as_null, append, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, gdal_tz_offsets, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;66;03m# preprocess kwargs and split in dataset and layer creation options\u001b[39;00m\n\u001b[0;32m    719\u001b[0m dataset_kwargs, layer_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_kwargs(\n\u001b[0;32m    720\u001b[0m     driver, dataset_options, layer_options, kwargs\n\u001b[0;32m    721\u001b[0m )\n\u001b[1;32m--> 723\u001b[0m \u001b[43mogr_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:2269\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_write\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You must provide at least a geometry column or a field"
     ]
    }
   ],
   "source": [
    "# output to geopandas\n",
    "# a = keyholemarkup2x('WA_400m_Grav_Merge_v1_2020.kmz',output='gpd')\n",
    "# plot this new file, use %matplotlib inline if you are in a notebook\n",
    "#%matplotlib inline\n",
    "# a.plot()\n",
    "# convert to shapefile\n",
    "a = keyholemarkup2x('WA_400m_Grav_Merge_v1_2020.kmz',output='shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "'WA_400m_Grav_Merge_v1_2020.kmz' not recognized as being in a supported file format. It might help to specify the correct driver explicitly by prefixing the file path with '<DRIVER>:', e.g. 'CSV:path'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWA_400m_Grav_Merge_v1_2020.kmz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\io\\file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\io\\file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    544\u001b[0m     )\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyogrio\\geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[0;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\joshc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyogrio\\raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:216\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDataSourceError\u001b[0m: 'WA_400m_Grav_Merge_v1_2020.kmz' not recognized as being in a supported file format. It might help to specify the correct driver explicitly by prefixing the file path with '<DRIVER>:', e.g. 'CSV:path'."
     ]
    }
   ],
   "source": [
    "data = gpd.read_file(\"WA_400m_Grav_Merge_v1_2020.kmz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drvsupport'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiona\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrvsupport\u001b[49m\u001b[38;5;241m.\u001b[39msupported_drivers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIBKMZ\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m fp\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWA_400m_Grav_Merge_v1_2020.kmz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m gdf_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drvsupport'"
     ]
    }
   ],
   "source": [
    "gpd.io.file.fiona.drvsupport.supported_drivers['LIBKMZ'] = 'rw'\n",
    "\n",
    "fp='WA_400m_Grav_Merge_v1_2020.kmz'\n",
    "\n",
    "gdf_list = []\n",
    "for layer in fiona.listlayers(fp):    \n",
    "    gdf = gpd.read_file(fp, driver='LIBKML', layer=layer)\n",
    "    gdf_list.append(gdf)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
